{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "keras.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BlueBug12/stock/blob/master/hw13_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfMKEx6zKSHG"
      },
      "source": [
        "# Keras\n",
        "\n",
        "[Keras](https://keras.io/) 是一種較 Tensorflow 更高階的深度學習框架，可以使用更少量的程式碼來建立深度學習模型，可以先熟悉 [Tensorflow 單元](/notebooks/unit/tensorflow/tenforflow.ipynb)後再來閱讀本單元。Keras 使用更低階的深度學習框架作為後端引擎，目前支援如 CNTK、Tensorflow、Theano 等知名框架。本單元將介紹 Keras 中 Model 與 Layer 的用法，並實作一個圖片分類器。\n",
        "\n",
        "## 1. Model & Layer\n",
        "\n",
        "在 Keras，可以宣告一個 [Model](https://keras.io/models/about-keras-models/) 物件，並透過加入一層一層的 [Layer](https://keras.io/layers/about-keras-layers/) 來建構一個神經網路，神經網路的運算(例如訓練)都可以透過該 Model 物件來操作。下方程式區段使用了 Keras 中常見的 [Sequential Model](https://keras.io/models/sequential/)，並加入了四種 Layer：\n",
        "\n",
        "1. [Convolutional Layer](https://keras.io/layers/convolutional/)：卷積層在影像、圖片應用上，表現比全連結層(Keras 的 Dense Layer 更為優異)，參考[卷積神經網絡介紹](https://medium.com/@yehjames/4f8249d65d4f)。\n",
        "2. [Pooling Layer](https://keras.io/layers/pooling/#maxpooling2d)：池化層的工作是降採樣(down sampling)，以下方程式區段使用的 MaxPooling 為例，將每個 2x2 降採樣為該區域的最大值。\n",
        "3. [Flatten Layer](https://keras.io/layers/core/#flatten)：將原本多維度的資料拉平成一維，目的是讓前一層的輸出可以接到下一層(通常是全連接層)的輸入。\n",
        "4. [Dense Layer](https://keras.io/layers/core/#dense)：全連結層。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeSIMwJFKSHH",
        "outputId": "d3bb74ab-6a31-4d28-bdee-0186f3c9cc39"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "\n",
        "model = Sequential() # Declare a sequential model\n",
        "\n",
        "# Add a 2D convolutional layer with 64 nodes, a 3x3 filter and relu as avtivation function\n",
        "# After this layer, `model.output_shape` is (None, 62, 62, 64)\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
        "\n",
        "# Add a 2D max pooling layer that pools the maximun value every 2x2 area\n",
        "# After this layer, `model.output_shape` is (None, 31, 31, 64)\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Add a flatten layer\n",
        "# After this layer, `model.output_shape` is (None, 61504)\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a dense layer with 32 nodes and sigmoid as activation function\n",
        "# After this layer, `model.output_shape` is (None, 32)\n",
        "model.add(Dense(32, activation='sigmoid'))\n",
        "\n",
        "# See `model`\n",
        "model.summary() "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 62, 62, 64)        1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 31, 31, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 61504)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1968160   \n",
            "=================================================================\n",
            "Total params: 1,969,952\n",
            "Trainable params: 1,969,952\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPr4u6ADKSHI"
      },
      "source": [
        "## 2. CIFAR-10\n",
        "\n",
        "CIFAR 的全名為 Canadian Institute for Advanced Research，是由加拿大政府出資並由多位科學家、工程師收集而成的圖片資料庫。[CIFAR-10](http://www.cs.toronto.edu/~kriz/cifar.html) 包含 60000 張 32x32x3 的 RGB 彩色圖片，其中 50000 張為訓練資料，10000 張為測試資料。CIFAR-10 有 10 種類別，0~9 分別對應為：\n",
        "\n",
        "```\n",
        "airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
        "```\n",
        "\n",
        "![CIFAR-10](./cifar_10.png)\n",
        "\n",
        "Keras 提供[整理好的 CIFAR-10 資料](https://keras.io/datasets/#cifar10-small-image-classification)，只要透過 `import` 就可以拿到對應的訓練與測試資料。用法如下："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "Yjtheix7KSHJ",
        "outputId": "258759cb-f154-4536-bd21-3c34eabf8dda"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# see the data shape\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "print()\n",
        "\n",
        "# show the i-th sample of the cifar-10 training set, try a different `i`\n",
        "i = 0\n",
        "plt.imshow(x_train[i])\n",
        "print('The label of training sample %d is %s.' % (i, y_train[i]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "(50000, 32, 32, 3) (50000, 1)\n",
            "(10000, 32, 32, 3) (10000, 1)\n",
            "\n",
            "The label of training sample 0 is [6].\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZsasu22KSHJ"
      },
      "source": [
        "## 3. 範例模型\n",
        "\n",
        "以下使用 Keras 實作兩種深度學習模型來進行 CIFAR-10 圖片分類。其中 DNN 只使用全連接層，而 CNN 多使用了卷積層。相較於 [Tensorflow 單元](/notebooks/unit/tensorflow/tenforflow.ipynb)的 MNIST 資料，CIFAR-10 的圖片比較複雜且為彩色，更能發揮卷積層的效果。也因此相較於 DNN，CNN 應該更容易得到好的結果。注意比較以下兩個程式區段，使用 CNN 時不需要將圖片 reshape 為一維向量。當然，CNN 也能處理 reshape 過的一維向量。CNN 的初學者可以參考以下連結：\n",
        "\n",
        "* [A Beginner's Guide To Understanding Convolutional Neural Networks](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/)\n",
        "* [深度學習(2)--使用Tensorflow實作卷積神經網路(Convolutional neural network，CNN)](http://arbu00.blogspot.tw/2017/03/2-tensorflowconvolutional-neural.html)\n",
        "\n",
        "![Convolutional Neural Network](https://adeshpande3.github.io/assets/Cover.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8aHoc-8KSHJ",
        "outputId": "efec8d9f-6a16-4d9d-a83c-e3a24bdb6ff3"
      },
      "source": [
        "# DNN\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "\n",
        "x_tr_dnn = x_train[:10000].astype('float32')\n",
        "x_te_dnn = x_test.astype('float32')\n",
        "\n",
        "# note that the CNN version does not need to reshape the input\n",
        "x_tr_dnn = x_tr_dnn.reshape(-1, 3072)\n",
        "x_te_dnn = x_te_dnn.reshape(-1, 3072)\n",
        "\n",
        "# normalize\n",
        "x_tr_dnn /= 255\n",
        "x_te_dnn /= 255\n",
        "\n",
        "# one-hot encoding\n",
        "y_tr_dnn = to_categorical(y_train[:10000], num_classes=10)\n",
        "y_te_dnn = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# options\n",
        "epochs = 20\n",
        "batch_size = 128 \n",
        "learning_rate = 0.001\n",
        "\n",
        "# model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_shape=(3072,)))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "\n",
        "# train\n",
        "model.fit(x_tr_dnn, y_tr_dnn, batch_size=batch_size, epochs=epochs, shuffle=True, validation_data=(x_te_dnn, y_te_dnn))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 2.1739 - accuracy: 0.2080 - val_loss: 2.0037 - val_accuracy: 0.2761\n",
            "Epoch 2/20\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 1.9803 - accuracy: 0.2853 - val_loss: 1.9444 - val_accuracy: 0.2993\n",
            "Epoch 3/20\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.9128 - accuracy: 0.3151 - val_loss: 1.8957 - val_accuracy: 0.3260\n",
            "Epoch 4/20\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.8442 - accuracy: 0.3476 - val_loss: 1.8586 - val_accuracy: 0.3384\n",
            "Epoch 5/20\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.7992 - accuracy: 0.3655 - val_loss: 1.8229 - val_accuracy: 0.3558\n",
            "Epoch 6/20\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.7667 - accuracy: 0.3773 - val_loss: 1.8281 - val_accuracy: 0.3514\n",
            "Epoch 7/20\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.7484 - accuracy: 0.3805 - val_loss: 1.8121 - val_accuracy: 0.3513\n",
            "Epoch 8/20\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.7242 - accuracy: 0.3911 - val_loss: 1.8237 - val_accuracy: 0.3566\n",
            "Epoch 9/20\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.7051 - accuracy: 0.3993 - val_loss: 1.7712 - val_accuracy: 0.3750\n",
            "Epoch 10/20\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6815 - accuracy: 0.4057 - val_loss: 1.7557 - val_accuracy: 0.3780\n",
            "Epoch 11/20\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6702 - accuracy: 0.4112 - val_loss: 1.8020 - val_accuracy: 0.3622\n",
            "Epoch 12/20\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6693 - accuracy: 0.4155 - val_loss: 1.7835 - val_accuracy: 0.3657\n",
            "Epoch 13/20\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6447 - accuracy: 0.4222 - val_loss: 1.7687 - val_accuracy: 0.3773\n",
            "Epoch 14/20\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6357 - accuracy: 0.4245 - val_loss: 1.7654 - val_accuracy: 0.3771\n",
            "Epoch 15/20\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6279 - accuracy: 0.4317 - val_loss: 1.8005 - val_accuracy: 0.3612\n",
            "Epoch 16/20\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6250 - accuracy: 0.4325 - val_loss: 1.7338 - val_accuracy: 0.3835\n",
            "Epoch 17/20\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5939 - accuracy: 0.4418 - val_loss: 1.7502 - val_accuracy: 0.3758\n",
            "Epoch 18/20\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.5982 - accuracy: 0.4381 - val_loss: 1.7280 - val_accuracy: 0.3855\n",
            "Epoch 19/20\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.5813 - accuracy: 0.4505 - val_loss: 1.7146 - val_accuracy: 0.3903\n",
            "Epoch 20/20\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5838 - accuracy: 0.4445 - val_loss: 1.8032 - val_accuracy: 0.3661\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4826a9f518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4hx2ylaKSHJ",
        "outputId": "13584dde-4107-4972-fe6c-8a7aae726ed8"
      },
      "source": [
        "# CNN\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "from keras.callbacks import EarlyStopping\n",
        "x_tr_cnn = x_train[:50000].astype('float32')\n",
        "x_te_cnn = x_test.astype('float32')\n",
        "\n",
        "# normalize\n",
        "x_tr_cnn /= 255\n",
        "x_te_cnn /= 255\n",
        "\n",
        "# one-hot encoding\n",
        "y_tr_cnn = to_categorical(y_train[:50000], num_classes=10)\n",
        "y_te_cnn = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# options\n",
        "epochs = 500\n",
        "batch_size = 128 \n",
        "learning_rate = 0.001\n",
        "\n",
        "# model\n",
        "model = Sequential()\n",
        "\n",
        "# the input shape for cifar-10 is (32, 32, 3)\n",
        "# use `Conv2D(#neurons, (filter_size))` to add convolutionary layers\n",
        "model.add(Conv2D(64, (3, 3), input_shape=(32, 32, 3),padding='same', activation='relu'))\n",
        "\n",
        "# use `MaxPooling2D()` to add pooling layers\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2),strides=(2,2)))\n",
        "model.add(Conv2D(128, (3, 3), padding='same',activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2),strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(256, (3, 3), padding='same',activation='relu'))\n",
        "model.add(Conv2D(256, (3, 3), padding='same',activation='relu'))\n",
        "model.add(Conv2D(256, (3, 3), padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2),strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(256, (3, 3), padding='same',activation='relu'))\n",
        "model.add(Conv2D(256, (3, 3), padding='same',activation='relu'))\n",
        "model.add(Conv2D(256, (3, 3), padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2),strides=(2,2)))\n",
        "'''\n",
        "model.add(Conv2D(512, (3, 3), padding='same',activation='relu'))\n",
        "model.add(Conv2D(512, (3, 3), padding='same',activation='relu'))\n",
        "model.add(Conv2D(512, (3, 3), padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2),strides=(2,2)))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',activation='relu'))\n",
        "model.add(Conv2D(512, (3, 3), padding='same',activation='relu'))\n",
        "model.add(Conv2D(512, (3, 3), padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2),strides=(2,2)))\n",
        "'''\n",
        "#model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# TODO: add more convolutionary and/or pooling layers here\n",
        "\n",
        "# in practice, fully-connected layers are added after convolutionary and pooling ones \n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "#model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "#model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "# train\n",
        "callback = EarlyStopping(monitor=\"val_accuracy\", patience=10, verbose=1, mode=\"auto\")\n",
        "#model.fit(x_tr_cnn, y_tr_cnn, batch_size=batch_size, epochs=epochs, shuffle=True, validation_data=(x_te_cnn, y_te_cnn), callbacks=[callback])\n",
        "model.fit(x_tr_cnn, y_tr_cnn, batch_size=batch_size, epochs=epochs, shuffle=True, validation_data=(x_te_cnn, y_te_cnn))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "  1/391 [..............................] - ETA: 11s - loss: 2.3041 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0159s vs `on_train_batch_end` time: 0.0299s). Check your callbacks.\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 2.3023 - accuracy: 0.1091 - val_loss: 2.3021 - val_accuracy: 0.1162\n",
            "Epoch 2/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 2.3006 - accuracy: 0.1437 - val_loss: 2.3000 - val_accuracy: 0.1046\n",
            "Epoch 3/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 2.2911 - accuracy: 0.1659 - val_loss: 2.2795 - val_accuracy: 0.1803\n",
            "Epoch 4/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 2.1897 - accuracy: 0.1894 - val_loss: 2.0956 - val_accuracy: 0.2354\n",
            "Epoch 5/500\n",
            "391/391 [==============================] - 13s 32ms/step - loss: 2.0697 - accuracy: 0.2319 - val_loss: 2.0992 - val_accuracy: 0.2303\n",
            "Epoch 6/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 2.0068 - accuracy: 0.2533 - val_loss: 1.9370 - val_accuracy: 0.2806\n",
            "Epoch 7/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.9452 - accuracy: 0.2702 - val_loss: 1.8637 - val_accuracy: 0.3006\n",
            "Epoch 8/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.8793 - accuracy: 0.2951 - val_loss: 1.8482 - val_accuracy: 0.3072\n",
            "Epoch 9/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.8258 - accuracy: 0.3134 - val_loss: 1.7460 - val_accuracy: 0.3396\n",
            "Epoch 10/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.7679 - accuracy: 0.3405 - val_loss: 1.6870 - val_accuracy: 0.3647\n",
            "Epoch 11/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.7149 - accuracy: 0.3566 - val_loss: 1.6202 - val_accuracy: 0.3879\n",
            "Epoch 12/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.6686 - accuracy: 0.3755 - val_loss: 1.5953 - val_accuracy: 0.4062\n",
            "Epoch 13/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.6245 - accuracy: 0.3926 - val_loss: 1.8428 - val_accuracy: 0.3393\n",
            "Epoch 14/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.5867 - accuracy: 0.4083 - val_loss: 1.5569 - val_accuracy: 0.4148\n",
            "Epoch 15/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.5492 - accuracy: 0.4249 - val_loss: 1.4599 - val_accuracy: 0.4524\n",
            "Epoch 16/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.5030 - accuracy: 0.4404 - val_loss: 1.4477 - val_accuracy: 0.4611\n",
            "Epoch 17/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.4663 - accuracy: 0.4566 - val_loss: 1.4294 - val_accuracy: 0.4685\n",
            "Epoch 18/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.4277 - accuracy: 0.4724 - val_loss: 1.4975 - val_accuracy: 0.4462\n",
            "Epoch 19/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.3918 - accuracy: 0.4862 - val_loss: 1.3677 - val_accuracy: 0.5000\n",
            "Epoch 20/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.3586 - accuracy: 0.5004 - val_loss: 1.3252 - val_accuracy: 0.5169\n",
            "Epoch 21/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.3192 - accuracy: 0.5155 - val_loss: 1.2425 - val_accuracy: 0.5482\n",
            "Epoch 22/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.2937 - accuracy: 0.5261 - val_loss: 1.2887 - val_accuracy: 0.5254\n",
            "Epoch 23/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.2632 - accuracy: 0.5378 - val_loss: 1.2868 - val_accuracy: 0.5309\n",
            "Epoch 24/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.2327 - accuracy: 0.5489 - val_loss: 1.1729 - val_accuracy: 0.5723\n",
            "Epoch 25/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.2049 - accuracy: 0.5590 - val_loss: 1.1618 - val_accuracy: 0.5812\n",
            "Epoch 26/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.1808 - accuracy: 0.5713 - val_loss: 1.1395 - val_accuracy: 0.5850\n",
            "Epoch 27/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.1542 - accuracy: 0.5806 - val_loss: 1.3422 - val_accuracy: 0.5365\n",
            "Epoch 28/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.1279 - accuracy: 0.5907 - val_loss: 1.0963 - val_accuracy: 0.6031\n",
            "Epoch 29/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.1078 - accuracy: 0.5945 - val_loss: 1.1141 - val_accuracy: 0.5984\n",
            "Epoch 30/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.0855 - accuracy: 0.6068 - val_loss: 1.0334 - val_accuracy: 0.6256\n",
            "Epoch 31/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.0618 - accuracy: 0.6158 - val_loss: 1.0536 - val_accuracy: 0.6265\n",
            "Epoch 32/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.0393 - accuracy: 0.6230 - val_loss: 1.0240 - val_accuracy: 0.6311\n",
            "Epoch 33/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.0171 - accuracy: 0.6301 - val_loss: 0.9927 - val_accuracy: 0.6463\n",
            "Epoch 34/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.9965 - accuracy: 0.6417 - val_loss: 0.9601 - val_accuracy: 0.6566\n",
            "Epoch 35/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.9806 - accuracy: 0.6463 - val_loss: 0.9635 - val_accuracy: 0.6563\n",
            "Epoch 36/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.9574 - accuracy: 0.6546 - val_loss: 0.9299 - val_accuracy: 0.6654\n",
            "Epoch 37/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.9352 - accuracy: 0.6643 - val_loss: 0.9101 - val_accuracy: 0.6778\n",
            "Epoch 38/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.9150 - accuracy: 0.6695 - val_loss: 1.2029 - val_accuracy: 0.5984\n",
            "Epoch 39/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.8990 - accuracy: 0.6761 - val_loss: 0.9103 - val_accuracy: 0.6799\n",
            "Epoch 40/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.8748 - accuracy: 0.6875 - val_loss: 0.9105 - val_accuracy: 0.6754\n",
            "Epoch 41/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.8619 - accuracy: 0.6908 - val_loss: 0.9001 - val_accuracy: 0.6805\n",
            "Epoch 42/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.8441 - accuracy: 0.6975 - val_loss: 0.8910 - val_accuracy: 0.6828\n",
            "Epoch 43/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.8278 - accuracy: 0.7036 - val_loss: 0.9475 - val_accuracy: 0.6658\n",
            "Epoch 44/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.8079 - accuracy: 0.7090 - val_loss: 0.8018 - val_accuracy: 0.7164\n",
            "Epoch 45/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.7894 - accuracy: 0.7210 - val_loss: 0.8939 - val_accuracy: 0.6949\n",
            "Epoch 46/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.7770 - accuracy: 0.7223 - val_loss: 0.8197 - val_accuracy: 0.7156\n",
            "Epoch 47/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.7591 - accuracy: 0.7304 - val_loss: 0.7560 - val_accuracy: 0.7341\n",
            "Epoch 48/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.7481 - accuracy: 0.7349 - val_loss: 0.8613 - val_accuracy: 0.6987\n",
            "Epoch 49/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.7253 - accuracy: 0.7428 - val_loss: 0.7930 - val_accuracy: 0.7282\n",
            "Epoch 50/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.7141 - accuracy: 0.7448 - val_loss: 0.7491 - val_accuracy: 0.7351\n",
            "Epoch 51/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.7052 - accuracy: 0.7494 - val_loss: 0.7530 - val_accuracy: 0.7429\n",
            "Epoch 52/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.6882 - accuracy: 0.7551 - val_loss: 0.7330 - val_accuracy: 0.7402\n",
            "Epoch 53/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.6699 - accuracy: 0.7623 - val_loss: 0.7719 - val_accuracy: 0.7336\n",
            "Epoch 54/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.6684 - accuracy: 0.7636 - val_loss: 0.7152 - val_accuracy: 0.7553\n",
            "Epoch 55/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.6505 - accuracy: 0.7696 - val_loss: 0.8304 - val_accuracy: 0.7227\n",
            "Epoch 56/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.6419 - accuracy: 0.7703 - val_loss: 0.7138 - val_accuracy: 0.7506\n",
            "Epoch 57/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.6313 - accuracy: 0.7749 - val_loss: 0.7111 - val_accuracy: 0.7576\n",
            "Epoch 58/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.6218 - accuracy: 0.7796 - val_loss: 0.7173 - val_accuracy: 0.7578\n",
            "Epoch 59/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.6099 - accuracy: 0.7853 - val_loss: 0.6990 - val_accuracy: 0.7606\n",
            "Epoch 60/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.5989 - accuracy: 0.7875 - val_loss: 0.7528 - val_accuracy: 0.7427\n",
            "Epoch 61/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.5954 - accuracy: 0.7897 - val_loss: 0.7023 - val_accuracy: 0.7556\n",
            "Epoch 62/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.5833 - accuracy: 0.7932 - val_loss: 0.6894 - val_accuracy: 0.7689\n",
            "Epoch 63/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.5716 - accuracy: 0.7987 - val_loss: 0.6375 - val_accuracy: 0.7805\n",
            "Epoch 64/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.5643 - accuracy: 0.8001 - val_loss: 0.6805 - val_accuracy: 0.7670\n",
            "Epoch 65/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.5551 - accuracy: 0.8037 - val_loss: 0.6560 - val_accuracy: 0.7756\n",
            "Epoch 66/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.5463 - accuracy: 0.8070 - val_loss: 0.6633 - val_accuracy: 0.7718\n",
            "Epoch 67/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.5369 - accuracy: 0.8101 - val_loss: 0.6465 - val_accuracy: 0.7852\n",
            "Epoch 68/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.5277 - accuracy: 0.8146 - val_loss: 0.7835 - val_accuracy: 0.7483\n",
            "Epoch 69/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.5218 - accuracy: 0.8159 - val_loss: 0.6429 - val_accuracy: 0.7828\n",
            "Epoch 70/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.5164 - accuracy: 0.8169 - val_loss: 0.6170 - val_accuracy: 0.7968\n",
            "Epoch 71/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.5040 - accuracy: 0.8215 - val_loss: 0.6340 - val_accuracy: 0.7887\n",
            "Epoch 72/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.4935 - accuracy: 0.8247 - val_loss: 0.6239 - val_accuracy: 0.7898\n",
            "Epoch 73/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.4882 - accuracy: 0.8278 - val_loss: 0.5903 - val_accuracy: 0.8026\n",
            "Epoch 74/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.4815 - accuracy: 0.8305 - val_loss: 0.7471 - val_accuracy: 0.7590\n",
            "Epoch 75/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.4786 - accuracy: 0.8322 - val_loss: 0.6942 - val_accuracy: 0.7772\n",
            "Epoch 76/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.4676 - accuracy: 0.8346 - val_loss: 0.6018 - val_accuracy: 0.8045\n",
            "Epoch 77/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.4655 - accuracy: 0.8349 - val_loss: 0.6763 - val_accuracy: 0.7769\n",
            "Epoch 78/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.4540 - accuracy: 0.8395 - val_loss: 0.6539 - val_accuracy: 0.7901\n",
            "Epoch 79/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.4496 - accuracy: 0.8405 - val_loss: 0.6667 - val_accuracy: 0.7858\n",
            "Epoch 80/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.4446 - accuracy: 0.8420 - val_loss: 0.5833 - val_accuracy: 0.8080\n",
            "Epoch 81/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.4374 - accuracy: 0.8447 - val_loss: 0.6836 - val_accuracy: 0.7794\n",
            "Epoch 82/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.4254 - accuracy: 0.8484 - val_loss: 0.5822 - val_accuracy: 0.8093\n",
            "Epoch 83/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.4237 - accuracy: 0.8494 - val_loss: 0.6178 - val_accuracy: 0.8024\n",
            "Epoch 84/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.4197 - accuracy: 0.8495 - val_loss: 0.6291 - val_accuracy: 0.7982\n",
            "Epoch 85/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.4131 - accuracy: 0.8535 - val_loss: 0.5817 - val_accuracy: 0.8137\n",
            "Epoch 86/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.4084 - accuracy: 0.8543 - val_loss: 0.6223 - val_accuracy: 0.8038\n",
            "Epoch 87/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3968 - accuracy: 0.8585 - val_loss: 0.6091 - val_accuracy: 0.8073\n",
            "Epoch 88/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3991 - accuracy: 0.8579 - val_loss: 0.5918 - val_accuracy: 0.8105\n",
            "Epoch 89/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3886 - accuracy: 0.8614 - val_loss: 0.6891 - val_accuracy: 0.7836\n",
            "Epoch 90/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3821 - accuracy: 0.8652 - val_loss: 0.6386 - val_accuracy: 0.7954\n",
            "Epoch 91/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3812 - accuracy: 0.8640 - val_loss: 0.5911 - val_accuracy: 0.8085\n",
            "Epoch 92/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3706 - accuracy: 0.8681 - val_loss: 0.5700 - val_accuracy: 0.8145\n",
            "Epoch 93/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3674 - accuracy: 0.8702 - val_loss: 0.6250 - val_accuracy: 0.8057\n",
            "Epoch 94/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3610 - accuracy: 0.8725 - val_loss: 0.5897 - val_accuracy: 0.8157\n",
            "Epoch 95/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3554 - accuracy: 0.8733 - val_loss: 0.5565 - val_accuracy: 0.8247\n",
            "Epoch 96/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3518 - accuracy: 0.8747 - val_loss: 0.6278 - val_accuracy: 0.8051\n",
            "Epoch 97/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3444 - accuracy: 0.8772 - val_loss: 0.7216 - val_accuracy: 0.7889\n",
            "Epoch 98/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3441 - accuracy: 0.8784 - val_loss: 0.5729 - val_accuracy: 0.8220\n",
            "Epoch 99/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3358 - accuracy: 0.8795 - val_loss: 0.6172 - val_accuracy: 0.8068\n",
            "Epoch 100/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3319 - accuracy: 0.8808 - val_loss: 0.5515 - val_accuracy: 0.8291\n",
            "Epoch 101/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3241 - accuracy: 0.8844 - val_loss: 0.5911 - val_accuracy: 0.8133\n",
            "Epoch 102/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3271 - accuracy: 0.8831 - val_loss: 0.5928 - val_accuracy: 0.8184\n",
            "Epoch 103/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3191 - accuracy: 0.8863 - val_loss: 0.5803 - val_accuracy: 0.8209\n",
            "Epoch 104/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3129 - accuracy: 0.8884 - val_loss: 0.5938 - val_accuracy: 0.8202\n",
            "Epoch 105/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3061 - accuracy: 0.8907 - val_loss: 0.5963 - val_accuracy: 0.8219\n",
            "Epoch 106/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3069 - accuracy: 0.8895 - val_loss: 0.5540 - val_accuracy: 0.8284\n",
            "Epoch 107/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.3000 - accuracy: 0.8934 - val_loss: 0.6110 - val_accuracy: 0.8166\n",
            "Epoch 108/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2905 - accuracy: 0.8963 - val_loss: 0.5862 - val_accuracy: 0.8236\n",
            "Epoch 109/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2894 - accuracy: 0.8968 - val_loss: 0.6169 - val_accuracy: 0.8199\n",
            "Epoch 110/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2895 - accuracy: 0.8968 - val_loss: 0.5701 - val_accuracy: 0.8270\n",
            "Epoch 111/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2837 - accuracy: 0.8997 - val_loss: 0.6111 - val_accuracy: 0.8214\n",
            "Epoch 112/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2818 - accuracy: 0.8988 - val_loss: 0.6069 - val_accuracy: 0.8186\n",
            "Epoch 113/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2707 - accuracy: 0.9037 - val_loss: 0.5831 - val_accuracy: 0.8294\n",
            "Epoch 115/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2643 - accuracy: 0.9042 - val_loss: 0.5884 - val_accuracy: 0.8239\n",
            "Epoch 116/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2643 - accuracy: 0.9068 - val_loss: 0.6677 - val_accuracy: 0.8082\n",
            "Epoch 117/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2631 - accuracy: 0.9069 - val_loss: 0.5731 - val_accuracy: 0.8316\n",
            "Epoch 118/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2513 - accuracy: 0.9100 - val_loss: 0.5789 - val_accuracy: 0.8327\n",
            "Epoch 119/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2480 - accuracy: 0.9103 - val_loss: 0.6256 - val_accuracy: 0.8240\n",
            "Epoch 120/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2509 - accuracy: 0.9098 - val_loss: 0.6112 - val_accuracy: 0.8256\n",
            "Epoch 121/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2502 - accuracy: 0.9108 - val_loss: 0.6126 - val_accuracy: 0.8254\n",
            "Epoch 122/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2436 - accuracy: 0.9128 - val_loss: 0.6012 - val_accuracy: 0.8295\n",
            "Epoch 123/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2348 - accuracy: 0.9152 - val_loss: 0.5947 - val_accuracy: 0.8260\n",
            "Epoch 124/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2361 - accuracy: 0.9159 - val_loss: 0.5959 - val_accuracy: 0.8290\n",
            "Epoch 125/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2325 - accuracy: 0.9168 - val_loss: 0.5575 - val_accuracy: 0.8368\n",
            "Epoch 126/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2272 - accuracy: 0.9185 - val_loss: 0.6188 - val_accuracy: 0.8294\n",
            "Epoch 127/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2269 - accuracy: 0.9174 - val_loss: 0.5674 - val_accuracy: 0.8342\n",
            "Epoch 128/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2224 - accuracy: 0.9193 - val_loss: 0.6331 - val_accuracy: 0.8209\n",
            "Epoch 129/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2204 - accuracy: 0.9209 - val_loss: 0.6227 - val_accuracy: 0.8237\n",
            "Epoch 130/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2183 - accuracy: 0.9219 - val_loss: 0.6772 - val_accuracy: 0.8184\n",
            "Epoch 131/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2123 - accuracy: 0.9246 - val_loss: 0.5964 - val_accuracy: 0.8347\n",
            "Epoch 132/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2106 - accuracy: 0.9257 - val_loss: 0.6610 - val_accuracy: 0.8250\n",
            "Epoch 133/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2101 - accuracy: 0.9244 - val_loss: 0.5630 - val_accuracy: 0.8417\n",
            "Epoch 134/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2041 - accuracy: 0.9275 - val_loss: 0.5899 - val_accuracy: 0.8384\n",
            "Epoch 135/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1991 - accuracy: 0.9282 - val_loss: 0.6626 - val_accuracy: 0.8287\n",
            "Epoch 136/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.2016 - accuracy: 0.9270 - val_loss: 0.5896 - val_accuracy: 0.8356\n",
            "Epoch 137/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1941 - accuracy: 0.9305 - val_loss: 0.5779 - val_accuracy: 0.8381\n",
            "Epoch 138/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1956 - accuracy: 0.9293 - val_loss: 0.5836 - val_accuracy: 0.8386\n",
            "Epoch 139/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1902 - accuracy: 0.9307 - val_loss: 0.5926 - val_accuracy: 0.8387\n",
            "Epoch 140/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1867 - accuracy: 0.9328 - val_loss: 0.6002 - val_accuracy: 0.8374\n",
            "Epoch 141/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1824 - accuracy: 0.9339 - val_loss: 0.6026 - val_accuracy: 0.8347\n",
            "Epoch 142/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1849 - accuracy: 0.9340 - val_loss: 0.6339 - val_accuracy: 0.8341\n",
            "Epoch 143/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1836 - accuracy: 0.9335 - val_loss: 0.6002 - val_accuracy: 0.8383\n",
            "Epoch 144/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1780 - accuracy: 0.9353 - val_loss: 0.7144 - val_accuracy: 0.8255\n",
            "Epoch 145/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1754 - accuracy: 0.9377 - val_loss: 0.6555 - val_accuracy: 0.8324\n",
            "Epoch 146/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1696 - accuracy: 0.9384 - val_loss: 0.6029 - val_accuracy: 0.8385\n",
            "Epoch 147/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1668 - accuracy: 0.9398 - val_loss: 0.6613 - val_accuracy: 0.8278\n",
            "Epoch 148/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1689 - accuracy: 0.9387 - val_loss: 0.6243 - val_accuracy: 0.8404\n",
            "Epoch 149/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1699 - accuracy: 0.9382 - val_loss: 0.6148 - val_accuracy: 0.8415\n",
            "Epoch 150/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1617 - accuracy: 0.9421 - val_loss: 0.8432 - val_accuracy: 0.7969\n",
            "Epoch 151/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1631 - accuracy: 0.9409 - val_loss: 0.6508 - val_accuracy: 0.8387\n",
            "Epoch 152/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1588 - accuracy: 0.9431 - val_loss: 0.6495 - val_accuracy: 0.8286\n",
            "Epoch 153/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1590 - accuracy: 0.9433 - val_loss: 0.5895 - val_accuracy: 0.8438\n",
            "Epoch 154/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1550 - accuracy: 0.9430 - val_loss: 0.6452 - val_accuracy: 0.8389\n",
            "Epoch 155/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1510 - accuracy: 0.9457 - val_loss: 0.6465 - val_accuracy: 0.8350\n",
            "Epoch 156/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1492 - accuracy: 0.9465 - val_loss: 0.6678 - val_accuracy: 0.8365\n",
            "Epoch 157/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1475 - accuracy: 0.9461 - val_loss: 0.7032 - val_accuracy: 0.8205\n",
            "Epoch 158/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1461 - accuracy: 0.9476 - val_loss: 0.6065 - val_accuracy: 0.8447\n",
            "Epoch 159/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1445 - accuracy: 0.9483 - val_loss: 0.7402 - val_accuracy: 0.8156\n",
            "Epoch 160/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1425 - accuracy: 0.9480 - val_loss: 0.6443 - val_accuracy: 0.8416\n",
            "Epoch 161/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1388 - accuracy: 0.9500 - val_loss: 0.6300 - val_accuracy: 0.8380\n",
            "Epoch 162/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1352 - accuracy: 0.9511 - val_loss: 0.6294 - val_accuracy: 0.8403\n",
            "Epoch 163/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1388 - accuracy: 0.9503 - val_loss: 0.7064 - val_accuracy: 0.8299\n",
            "Epoch 164/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1340 - accuracy: 0.9526 - val_loss: 0.6473 - val_accuracy: 0.8420\n",
            "Epoch 165/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1339 - accuracy: 0.9512 - val_loss: 0.6741 - val_accuracy: 0.8411\n",
            "Epoch 166/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1305 - accuracy: 0.9523 - val_loss: 0.6796 - val_accuracy: 0.8415\n",
            "Epoch 167/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1284 - accuracy: 0.9534 - val_loss: 0.6270 - val_accuracy: 0.8428\n",
            "Epoch 168/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1265 - accuracy: 0.9538 - val_loss: 0.6507 - val_accuracy: 0.8403\n",
            "Epoch 169/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1226 - accuracy: 0.9558 - val_loss: 0.6679 - val_accuracy: 0.8417\n",
            "Epoch 170/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1238 - accuracy: 0.9559 - val_loss: 0.6650 - val_accuracy: 0.8428\n",
            "Epoch 171/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1220 - accuracy: 0.9553 - val_loss: 0.6502 - val_accuracy: 0.8413\n",
            "Epoch 172/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1194 - accuracy: 0.9566 - val_loss: 0.6483 - val_accuracy: 0.8460\n",
            "Epoch 173/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1200 - accuracy: 0.9570 - val_loss: 0.6683 - val_accuracy: 0.8425\n",
            "Epoch 174/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1151 - accuracy: 0.9588 - val_loss: 0.6905 - val_accuracy: 0.8402\n",
            "Epoch 175/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1146 - accuracy: 0.9578 - val_loss: 0.7518 - val_accuracy: 0.8371\n",
            "Epoch 176/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1149 - accuracy: 0.9579 - val_loss: 0.6651 - val_accuracy: 0.8439\n",
            "Epoch 177/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1165 - accuracy: 0.9584 - val_loss: 0.6838 - val_accuracy: 0.8389\n",
            "Epoch 178/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1090 - accuracy: 0.9607 - val_loss: 0.7114 - val_accuracy: 0.8376\n",
            "Epoch 179/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1117 - accuracy: 0.9602 - val_loss: 0.6799 - val_accuracy: 0.8404\n",
            "Epoch 180/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1091 - accuracy: 0.9615 - val_loss: 0.6946 - val_accuracy: 0.8421\n",
            "Epoch 181/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1094 - accuracy: 0.9610 - val_loss: 0.6626 - val_accuracy: 0.8455\n",
            "Epoch 182/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1061 - accuracy: 0.9615 - val_loss: 0.7057 - val_accuracy: 0.8391\n",
            "Epoch 183/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1000 - accuracy: 0.9645 - val_loss: 0.7217 - val_accuracy: 0.8353\n",
            "Epoch 184/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1029 - accuracy: 0.9642 - val_loss: 0.7141 - val_accuracy: 0.8381\n",
            "Epoch 185/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1025 - accuracy: 0.9623 - val_loss: 0.6975 - val_accuracy: 0.8476\n",
            "Epoch 186/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0987 - accuracy: 0.9646 - val_loss: 0.6911 - val_accuracy: 0.8470\n",
            "Epoch 187/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1016 - accuracy: 0.9629 - val_loss: 0.7205 - val_accuracy: 0.8371\n",
            "Epoch 188/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0999 - accuracy: 0.9639 - val_loss: 0.7406 - val_accuracy: 0.8343\n",
            "Epoch 189/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.1041 - accuracy: 0.9631 - val_loss: 0.6891 - val_accuracy: 0.8392\n",
            "Epoch 190/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0973 - accuracy: 0.9655 - val_loss: 0.7010 - val_accuracy: 0.8443\n",
            "Epoch 191/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0956 - accuracy: 0.9665 - val_loss: 0.7324 - val_accuracy: 0.8394\n",
            "Epoch 192/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0971 - accuracy: 0.9655 - val_loss: 0.6846 - val_accuracy: 0.8463\n",
            "Epoch 193/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0966 - accuracy: 0.9649 - val_loss: 0.7473 - val_accuracy: 0.8411\n",
            "Epoch 194/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0857 - accuracy: 0.9694 - val_loss: 0.7091 - val_accuracy: 0.8449\n",
            "Epoch 195/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0937 - accuracy: 0.9659 - val_loss: 0.6954 - val_accuracy: 0.8460\n",
            "Epoch 196/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0914 - accuracy: 0.9676 - val_loss: 0.7310 - val_accuracy: 0.8427\n",
            "Epoch 197/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0885 - accuracy: 0.9685 - val_loss: 0.7115 - val_accuracy: 0.8481\n",
            "Epoch 198/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0891 - accuracy: 0.9684 - val_loss: 0.7275 - val_accuracy: 0.8454\n",
            "Epoch 199/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0896 - accuracy: 0.9681 - val_loss: 0.7182 - val_accuracy: 0.8421\n",
            "Epoch 200/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0852 - accuracy: 0.9696 - val_loss: 0.7254 - val_accuracy: 0.8450\n",
            "Epoch 201/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0884 - accuracy: 0.9680 - val_loss: 0.7246 - val_accuracy: 0.8463\n",
            "Epoch 202/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0827 - accuracy: 0.9696 - val_loss: 0.7382 - val_accuracy: 0.8455\n",
            "Epoch 203/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0844 - accuracy: 0.9695 - val_loss: 0.7587 - val_accuracy: 0.8410\n",
            "Epoch 204/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0857 - accuracy: 0.9694 - val_loss: 0.6911 - val_accuracy: 0.8482\n",
            "Epoch 205/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0814 - accuracy: 0.9705 - val_loss: 0.7142 - val_accuracy: 0.8490\n",
            "Epoch 206/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0829 - accuracy: 0.9700 - val_loss: 0.6915 - val_accuracy: 0.8448\n",
            "Epoch 207/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0782 - accuracy: 0.9718 - val_loss: 0.7532 - val_accuracy: 0.8453\n",
            "Epoch 208/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0811 - accuracy: 0.9711 - val_loss: 0.7403 - val_accuracy: 0.8435\n",
            "Epoch 209/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0756 - accuracy: 0.9729 - val_loss: 0.7440 - val_accuracy: 0.8433\n",
            "Epoch 210/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0774 - accuracy: 0.9723 - val_loss: 0.8094 - val_accuracy: 0.8376\n",
            "Epoch 211/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0743 - accuracy: 0.9737 - val_loss: 0.7231 - val_accuracy: 0.8468\n",
            "Epoch 212/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0756 - accuracy: 0.9735 - val_loss: 0.7159 - val_accuracy: 0.8477\n",
            "Epoch 213/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0710 - accuracy: 0.9745 - val_loss: 0.7920 - val_accuracy: 0.8374\n",
            "Epoch 214/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0747 - accuracy: 0.9742 - val_loss: 0.6983 - val_accuracy: 0.8571\n",
            "Epoch 215/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0747 - accuracy: 0.9737 - val_loss: 0.7344 - val_accuracy: 0.8484\n",
            "Epoch 216/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0726 - accuracy: 0.9738 - val_loss: 0.7297 - val_accuracy: 0.8464\n",
            "Epoch 217/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0720 - accuracy: 0.9741 - val_loss: 0.7567 - val_accuracy: 0.8463\n",
            "Epoch 218/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0723 - accuracy: 0.9744 - val_loss: 0.7268 - val_accuracy: 0.8528\n",
            "Epoch 219/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0707 - accuracy: 0.9748 - val_loss: 0.8022 - val_accuracy: 0.8392\n",
            "Epoch 220/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0727 - accuracy: 0.9739 - val_loss: 0.7013 - val_accuracy: 0.8539\n",
            "Epoch 221/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0674 - accuracy: 0.9765 - val_loss: 0.7030 - val_accuracy: 0.8516\n",
            "Epoch 222/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0691 - accuracy: 0.9757 - val_loss: 0.7363 - val_accuracy: 0.8446\n",
            "Epoch 223/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0637 - accuracy: 0.9769 - val_loss: 0.7304 - val_accuracy: 0.8526\n",
            "Epoch 224/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0661 - accuracy: 0.9766 - val_loss: 0.7174 - val_accuracy: 0.8514\n",
            "Epoch 225/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0664 - accuracy: 0.9763 - val_loss: 0.7158 - val_accuracy: 0.8505\n",
            "Epoch 226/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0652 - accuracy: 0.9770 - val_loss: 0.7569 - val_accuracy: 0.8491\n",
            "Epoch 227/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0652 - accuracy: 0.9777 - val_loss: 0.7594 - val_accuracy: 0.8484\n",
            "Epoch 228/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0658 - accuracy: 0.9765 - val_loss: 0.7334 - val_accuracy: 0.8538\n",
            "Epoch 229/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0658 - accuracy: 0.9768 - val_loss: 0.7539 - val_accuracy: 0.8475\n",
            "Epoch 230/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0621 - accuracy: 0.9778 - val_loss: 0.7328 - val_accuracy: 0.8526\n",
            "Epoch 231/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0631 - accuracy: 0.9773 - val_loss: 0.7312 - val_accuracy: 0.8518\n",
            "Epoch 232/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0596 - accuracy: 0.9788 - val_loss: 0.7433 - val_accuracy: 0.8532\n",
            "Epoch 233/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0642 - accuracy: 0.9770 - val_loss: 0.7363 - val_accuracy: 0.8510\n",
            "Epoch 234/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0591 - accuracy: 0.9792 - val_loss: 0.7300 - val_accuracy: 0.8530\n",
            "Epoch 235/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0577 - accuracy: 0.9796 - val_loss: 0.7515 - val_accuracy: 0.8501\n",
            "Epoch 236/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0592 - accuracy: 0.9788 - val_loss: 0.7105 - val_accuracy: 0.8547\n",
            "Epoch 238/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0585 - accuracy: 0.9796 - val_loss: 0.7176 - val_accuracy: 0.8535\n",
            "Epoch 239/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0609 - accuracy: 0.9787 - val_loss: 0.7845 - val_accuracy: 0.8479\n",
            "Epoch 240/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0587 - accuracy: 0.9792 - val_loss: 0.7426 - val_accuracy: 0.8555\n",
            "Epoch 241/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0555 - accuracy: 0.9805 - val_loss: 0.7756 - val_accuracy: 0.8516\n",
            "Epoch 242/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0585 - accuracy: 0.9789 - val_loss: 0.8105 - val_accuracy: 0.8456\n",
            "Epoch 243/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0553 - accuracy: 0.9795 - val_loss: 0.7498 - val_accuracy: 0.8550\n",
            "Epoch 244/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0573 - accuracy: 0.9805 - val_loss: 0.7539 - val_accuracy: 0.8516\n",
            "Epoch 245/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0584 - accuracy: 0.9796 - val_loss: 0.7225 - val_accuracy: 0.8556\n",
            "Epoch 246/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0557 - accuracy: 0.9803 - val_loss: 0.8118 - val_accuracy: 0.8442\n",
            "Epoch 247/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0539 - accuracy: 0.9810 - val_loss: 0.7665 - val_accuracy: 0.8548\n",
            "Epoch 248/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0555 - accuracy: 0.9807 - val_loss: 0.8093 - val_accuracy: 0.8448\n",
            "Epoch 249/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0552 - accuracy: 0.9803 - val_loss: 0.8296 - val_accuracy: 0.8466\n",
            "Epoch 250/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0541 - accuracy: 0.9807 - val_loss: 0.8027 - val_accuracy: 0.8454\n",
            "Epoch 251/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0529 - accuracy: 0.9815 - val_loss: 0.7778 - val_accuracy: 0.8499\n",
            "Epoch 252/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0524 - accuracy: 0.9806 - val_loss: 0.7800 - val_accuracy: 0.8477\n",
            "Epoch 253/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0523 - accuracy: 0.9817 - val_loss: 0.7680 - val_accuracy: 0.8558\n",
            "Epoch 254/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0519 - accuracy: 0.9819 - val_loss: 0.8092 - val_accuracy: 0.8493\n",
            "Epoch 255/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0494 - accuracy: 0.9830 - val_loss: 0.7996 - val_accuracy: 0.8508\n",
            "Epoch 256/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0504 - accuracy: 0.9826 - val_loss: 0.7855 - val_accuracy: 0.8506\n",
            "Epoch 257/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0485 - accuracy: 0.9827 - val_loss: 0.7684 - val_accuracy: 0.8544\n",
            "Epoch 258/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0505 - accuracy: 0.9824 - val_loss: 0.7732 - val_accuracy: 0.8526\n",
            "Epoch 259/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0493 - accuracy: 0.9832 - val_loss: 0.7752 - val_accuracy: 0.8552\n",
            "Epoch 260/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0477 - accuracy: 0.9825 - val_loss: 0.7896 - val_accuracy: 0.8542\n",
            "Epoch 261/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0464 - accuracy: 0.9839 - val_loss: 0.7794 - val_accuracy: 0.8541\n",
            "Epoch 262/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0448 - accuracy: 0.9844 - val_loss: 0.7717 - val_accuracy: 0.8562\n",
            "Epoch 263/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0466 - accuracy: 0.9833 - val_loss: 0.7605 - val_accuracy: 0.8568\n",
            "Epoch 264/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0465 - accuracy: 0.9837 - val_loss: 0.8092 - val_accuracy: 0.8515\n",
            "Epoch 265/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0470 - accuracy: 0.9836 - val_loss: 0.7762 - val_accuracy: 0.8541\n",
            "Epoch 266/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0449 - accuracy: 0.9847 - val_loss: 0.7797 - val_accuracy: 0.8587\n",
            "Epoch 267/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0469 - accuracy: 0.9832 - val_loss: 0.7801 - val_accuracy: 0.8486\n",
            "Epoch 268/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0442 - accuracy: 0.9837 - val_loss: 0.8249 - val_accuracy: 0.8479\n",
            "Epoch 269/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0452 - accuracy: 0.9845 - val_loss: 0.9404 - val_accuracy: 0.8368\n",
            "Epoch 270/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0491 - accuracy: 0.9829 - val_loss: 0.7961 - val_accuracy: 0.8511\n",
            "Epoch 271/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0454 - accuracy: 0.9840 - val_loss: 0.7908 - val_accuracy: 0.8498\n",
            "Epoch 272/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0469 - accuracy: 0.9833 - val_loss: 0.8384 - val_accuracy: 0.8491\n",
            "Epoch 273/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0427 - accuracy: 0.9849 - val_loss: 0.7962 - val_accuracy: 0.8499\n",
            "Epoch 274/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0442 - accuracy: 0.9846 - val_loss: 0.7952 - val_accuracy: 0.8523\n",
            "Epoch 275/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0420 - accuracy: 0.9850 - val_loss: 0.7885 - val_accuracy: 0.8569\n",
            "Epoch 276/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0418 - accuracy: 0.9847 - val_loss: 0.8546 - val_accuracy: 0.8489\n",
            "Epoch 277/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0438 - accuracy: 0.9839 - val_loss: 0.7824 - val_accuracy: 0.8563\n",
            "Epoch 278/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0437 - accuracy: 0.9846 - val_loss: 0.8033 - val_accuracy: 0.8537\n",
            "Epoch 279/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0396 - accuracy: 0.9859 - val_loss: 0.8166 - val_accuracy: 0.8484\n",
            "Epoch 280/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0414 - accuracy: 0.9856 - val_loss: 0.7947 - val_accuracy: 0.8539\n",
            "Epoch 281/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0439 - accuracy: 0.9849 - val_loss: 0.8266 - val_accuracy: 0.8510\n",
            "Epoch 282/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0425 - accuracy: 0.9851 - val_loss: 0.7890 - val_accuracy: 0.8540\n",
            "Epoch 283/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0416 - accuracy: 0.9864 - val_loss: 0.8593 - val_accuracy: 0.8475\n",
            "Epoch 284/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0388 - accuracy: 0.9862 - val_loss: 0.8037 - val_accuracy: 0.8551\n",
            "Epoch 285/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0390 - accuracy: 0.9868 - val_loss: 0.8143 - val_accuracy: 0.8556\n",
            "Epoch 286/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0393 - accuracy: 0.9862 - val_loss: 0.7847 - val_accuracy: 0.8542\n",
            "Epoch 287/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0397 - accuracy: 0.9860 - val_loss: 0.8223 - val_accuracy: 0.8537\n",
            "Epoch 290/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0398 - accuracy: 0.9858 - val_loss: 0.7810 - val_accuracy: 0.8552\n",
            "Epoch 291/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0392 - accuracy: 0.9862 - val_loss: 0.8166 - val_accuracy: 0.8515\n",
            "Epoch 292/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0400 - accuracy: 0.9860 - val_loss: 0.7980 - val_accuracy: 0.8546\n",
            "Epoch 293/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0371 - accuracy: 0.9865 - val_loss: 0.8831 - val_accuracy: 0.8458\n",
            "Epoch 294/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0395 - accuracy: 0.9862 - val_loss: 0.8506 - val_accuracy: 0.8501\n",
            "Epoch 295/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0368 - accuracy: 0.9868 - val_loss: 0.8221 - val_accuracy: 0.8544\n",
            "Epoch 296/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0375 - accuracy: 0.9870 - val_loss: 0.8411 - val_accuracy: 0.8533\n",
            "Epoch 297/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0379 - accuracy: 0.9866 - val_loss: 0.8384 - val_accuracy: 0.8556\n",
            "Epoch 298/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0378 - accuracy: 0.9870 - val_loss: 0.7728 - val_accuracy: 0.8558\n",
            "Epoch 299/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0379 - accuracy: 0.9866 - val_loss: 0.8596 - val_accuracy: 0.8446\n",
            "Epoch 300/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0367 - accuracy: 0.9873 - val_loss: 0.8213 - val_accuracy: 0.8543\n",
            "Epoch 301/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0358 - accuracy: 0.9878 - val_loss: 0.8025 - val_accuracy: 0.8570\n",
            "Epoch 302/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0362 - accuracy: 0.9876 - val_loss: 0.8847 - val_accuracy: 0.8466\n",
            "Epoch 303/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0370 - accuracy: 0.9872 - val_loss: 0.8130 - val_accuracy: 0.8553\n",
            "Epoch 304/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0351 - accuracy: 0.9879 - val_loss: 0.8607 - val_accuracy: 0.8489\n",
            "Epoch 305/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0321 - accuracy: 0.9885 - val_loss: 0.8500 - val_accuracy: 0.8553\n",
            "Epoch 306/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0340 - accuracy: 0.9873 - val_loss: 0.8386 - val_accuracy: 0.8562\n",
            "Epoch 307/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0337 - accuracy: 0.9888 - val_loss: 0.8451 - val_accuracy: 0.8546\n",
            "Epoch 308/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0369 - accuracy: 0.9873 - val_loss: 0.9121 - val_accuracy: 0.8434\n",
            "Epoch 309/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0373 - accuracy: 0.9875 - val_loss: 0.8169 - val_accuracy: 0.8550\n",
            "Epoch 310/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0344 - accuracy: 0.9875 - val_loss: 0.8682 - val_accuracy: 0.8467\n",
            "Epoch 311/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0356 - accuracy: 0.9875 - val_loss: 0.8553 - val_accuracy: 0.8503\n",
            "Epoch 312/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0306 - accuracy: 0.9895 - val_loss: 0.8059 - val_accuracy: 0.8550\n",
            "Epoch 313/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0346 - accuracy: 0.9887 - val_loss: 0.9374 - val_accuracy: 0.8447\n",
            "Epoch 314/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0333 - accuracy: 0.9886 - val_loss: 0.8426 - val_accuracy: 0.8546\n",
            "Epoch 315/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0339 - accuracy: 0.9884 - val_loss: 0.8340 - val_accuracy: 0.8551\n",
            "Epoch 316/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0343 - accuracy: 0.9884 - val_loss: 0.8117 - val_accuracy: 0.8562\n",
            "Epoch 317/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0324 - accuracy: 0.9888 - val_loss: 0.8976 - val_accuracy: 0.8459\n",
            "Epoch 318/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0308 - accuracy: 0.9893 - val_loss: 0.8137 - val_accuracy: 0.8580\n",
            "Epoch 319/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 0.8570 - val_accuracy: 0.8511\n",
            "Epoch 320/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0322 - accuracy: 0.9889 - val_loss: 0.8324 - val_accuracy: 0.8583\n",
            "Epoch 321/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0334 - accuracy: 0.9885 - val_loss: 0.8301 - val_accuracy: 0.8564\n",
            "Epoch 322/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0342 - accuracy: 0.9885 - val_loss: 0.8223 - val_accuracy: 0.8540\n",
            "Epoch 323/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0341 - accuracy: 0.9878 - val_loss: 0.8582 - val_accuracy: 0.8541\n",
            "Epoch 324/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0345 - accuracy: 0.9885 - val_loss: 0.7990 - val_accuracy: 0.8565\n",
            "Epoch 325/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0327 - accuracy: 0.9891 - val_loss: 0.8310 - val_accuracy: 0.8564\n",
            "Epoch 326/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0314 - accuracy: 0.9891 - val_loss: 0.8412 - val_accuracy: 0.8518\n",
            "Epoch 327/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0323 - accuracy: 0.9886 - val_loss: 0.8360 - val_accuracy: 0.8572\n",
            "Epoch 328/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0313 - accuracy: 0.9892 - val_loss: 0.7956 - val_accuracy: 0.8589\n",
            "Epoch 329/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0295 - accuracy: 0.9896 - val_loss: 0.8370 - val_accuracy: 0.8565\n",
            "Epoch 330/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0301 - accuracy: 0.9897 - val_loss: 0.9537 - val_accuracy: 0.8356\n",
            "Epoch 331/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0321 - accuracy: 0.9891 - val_loss: 0.8623 - val_accuracy: 0.8536\n",
            "Epoch 332/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0298 - accuracy: 0.9891 - val_loss: 0.8849 - val_accuracy: 0.8525\n",
            "Epoch 333/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0292 - accuracy: 0.9892 - val_loss: 0.8755 - val_accuracy: 0.8529\n",
            "Epoch 334/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0270 - accuracy: 0.9906 - val_loss: 0.9062 - val_accuracy: 0.8554\n",
            "Epoch 335/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0298 - accuracy: 0.9898 - val_loss: 0.8706 - val_accuracy: 0.8552\n",
            "Epoch 336/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0293 - accuracy: 0.9898 - val_loss: 0.8582 - val_accuracy: 0.8547\n",
            "Epoch 337/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0265 - accuracy: 0.9907 - val_loss: 0.8661 - val_accuracy: 0.8539\n",
            "Epoch 338/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0296 - accuracy: 0.9899 - val_loss: 0.8786 - val_accuracy: 0.8512\n",
            "Epoch 339/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0288 - accuracy: 0.9898 - val_loss: 0.8873 - val_accuracy: 0.8537\n",
            "Epoch 340/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0315 - accuracy: 0.9888 - val_loss: 0.8125 - val_accuracy: 0.8616\n",
            "Epoch 341/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0274 - accuracy: 0.9908 - val_loss: 0.8501 - val_accuracy: 0.8560\n",
            "Epoch 342/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0292 - accuracy: 0.9899 - val_loss: 0.8052 - val_accuracy: 0.8564\n",
            "Epoch 343/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0292 - accuracy: 0.9902 - val_loss: 0.9104 - val_accuracy: 0.8454\n",
            "Epoch 344/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0285 - accuracy: 0.9901 - val_loss: 0.8781 - val_accuracy: 0.8538\n",
            "Epoch 345/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0291 - accuracy: 0.9898 - val_loss: 0.8737 - val_accuracy: 0.8571\n",
            "Epoch 346/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0280 - accuracy: 0.9898 - val_loss: 0.8478 - val_accuracy: 0.8565\n",
            "Epoch 347/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0279 - accuracy: 0.9904 - val_loss: 0.8668 - val_accuracy: 0.8572\n",
            "Epoch 348/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0271 - accuracy: 0.9906 - val_loss: 0.8051 - val_accuracy: 0.8607\n",
            "Epoch 349/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0288 - accuracy: 0.9893 - val_loss: 0.9192 - val_accuracy: 0.8482\n",
            "Epoch 350/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0292 - accuracy: 0.9899 - val_loss: 0.8291 - val_accuracy: 0.8582\n",
            "Epoch 351/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0255 - accuracy: 0.9916 - val_loss: 0.8630 - val_accuracy: 0.8557\n",
            "Epoch 352/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0278 - accuracy: 0.9902 - val_loss: 0.8916 - val_accuracy: 0.8513\n",
            "Epoch 353/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0285 - accuracy: 0.9900 - val_loss: 0.8533 - val_accuracy: 0.8537\n",
            "Epoch 354/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0274 - accuracy: 0.9901 - val_loss: 0.8676 - val_accuracy: 0.8553\n",
            "Epoch 355/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0244 - accuracy: 0.9918 - val_loss: 0.8778 - val_accuracy: 0.8518\n",
            "Epoch 356/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0273 - accuracy: 0.9903 - val_loss: 0.8346 - val_accuracy: 0.8590\n",
            "Epoch 357/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0283 - accuracy: 0.9902 - val_loss: 0.8188 - val_accuracy: 0.8594\n",
            "Epoch 358/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0270 - accuracy: 0.9905 - val_loss: 0.8419 - val_accuracy: 0.8577\n",
            "Epoch 359/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0266 - accuracy: 0.9906 - val_loss: 0.8553 - val_accuracy: 0.8561\n",
            "Epoch 360/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0270 - accuracy: 0.9911 - val_loss: 0.9266 - val_accuracy: 0.8517\n",
            "Epoch 361/500\n",
            "391/391 [==============================] - 13s 32ms/step - loss: 0.0256 - accuracy: 0.9911 - val_loss: 0.8876 - val_accuracy: 0.8569\n",
            "Epoch 362/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0246 - accuracy: 0.9916 - val_loss: 0.9107 - val_accuracy: 0.8511\n",
            "Epoch 363/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0284 - accuracy: 0.9906 - val_loss: 0.8542 - val_accuracy: 0.8588\n",
            "Epoch 364/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0274 - accuracy: 0.9901 - val_loss: 0.9010 - val_accuracy: 0.8549\n",
            "Epoch 365/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.8665 - val_accuracy: 0.8566\n",
            "Epoch 366/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0244 - accuracy: 0.9914 - val_loss: 0.8670 - val_accuracy: 0.8565\n",
            "Epoch 367/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0241 - accuracy: 0.9913 - val_loss: 0.8609 - val_accuracy: 0.8584\n",
            "Epoch 368/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0280 - accuracy: 0.9903 - val_loss: 0.8830 - val_accuracy: 0.8555\n",
            "Epoch 369/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0256 - accuracy: 0.9910 - val_loss: 0.8617 - val_accuracy: 0.8582\n",
            "Epoch 370/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0279 - accuracy: 0.9902 - val_loss: 0.8453 - val_accuracy: 0.8590\n",
            "Epoch 371/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0247 - accuracy: 0.9914 - val_loss: 0.8958 - val_accuracy: 0.8515\n",
            "Epoch 372/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0242 - accuracy: 0.9913 - val_loss: 0.8610 - val_accuracy: 0.8597\n",
            "Epoch 373/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 0.8673 - val_accuracy: 0.8595\n",
            "Epoch 374/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 0.8404 - val_accuracy: 0.8574\n",
            "Epoch 375/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0230 - accuracy: 0.9918 - val_loss: 0.8961 - val_accuracy: 0.8590\n",
            "Epoch 376/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 0.8722 - val_accuracy: 0.8576\n",
            "Epoch 377/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0224 - accuracy: 0.9918 - val_loss: 0.8589 - val_accuracy: 0.8571\n",
            "Epoch 378/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0246 - accuracy: 0.9914 - val_loss: 0.8911 - val_accuracy: 0.8570\n",
            "Epoch 379/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0250 - accuracy: 0.9914 - val_loss: 0.8972 - val_accuracy: 0.8567\n",
            "Epoch 380/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.8940 - val_accuracy: 0.8563\n",
            "Epoch 381/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0259 - accuracy: 0.9909 - val_loss: 0.8755 - val_accuracy: 0.8550\n",
            "Epoch 382/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 0.8955 - val_accuracy: 0.8551\n",
            "Epoch 383/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 0.8819 - val_accuracy: 0.8538\n",
            "Epoch 384/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0236 - accuracy: 0.9917 - val_loss: 0.8724 - val_accuracy: 0.8558\n",
            "Epoch 385/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0231 - accuracy: 0.9921 - val_loss: 0.8926 - val_accuracy: 0.8570\n",
            "Epoch 386/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0244 - accuracy: 0.9922 - val_loss: 0.8895 - val_accuracy: 0.8570\n",
            "Epoch 387/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.9007 - val_accuracy: 0.8558\n",
            "Epoch 388/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0246 - accuracy: 0.9914 - val_loss: 0.8738 - val_accuracy: 0.8577\n",
            "Epoch 389/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.9185 - val_accuracy: 0.8528\n",
            "Epoch 390/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0224 - accuracy: 0.9921 - val_loss: 0.8872 - val_accuracy: 0.8604\n",
            "Epoch 391/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0222 - accuracy: 0.9923 - val_loss: 0.8255 - val_accuracy: 0.8601\n",
            "Epoch 392/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0233 - accuracy: 0.9920 - val_loss: 0.8691 - val_accuracy: 0.8568\n",
            "Epoch 393/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.9022 - val_accuracy: 0.8525\n",
            "Epoch 394/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0217 - accuracy: 0.9928 - val_loss: 0.8465 - val_accuracy: 0.8602\n",
            "Epoch 395/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0225 - accuracy: 0.9921 - val_loss: 0.9029 - val_accuracy: 0.8558\n",
            "Epoch 396/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0200 - accuracy: 0.9930 - val_loss: 0.9001 - val_accuracy: 0.8583\n",
            "Epoch 397/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.9055 - val_accuracy: 0.8575\n",
            "Epoch 398/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0243 - accuracy: 0.9914 - val_loss: 0.9229 - val_accuracy: 0.8536\n",
            "Epoch 399/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.8892 - val_accuracy: 0.8601\n",
            "Epoch 400/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0267 - accuracy: 0.9903 - val_loss: 0.8449 - val_accuracy: 0.8615\n",
            "Epoch 401/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.8975 - val_accuracy: 0.8555\n",
            "Epoch 402/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0221 - accuracy: 0.9923 - val_loss: 0.8784 - val_accuracy: 0.8583\n",
            "Epoch 403/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0214 - accuracy: 0.9930 - val_loss: 0.8659 - val_accuracy: 0.8574\n",
            "Epoch 404/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0236 - accuracy: 0.9919 - val_loss: 0.8841 - val_accuracy: 0.8573\n",
            "Epoch 405/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0202 - accuracy: 0.9929 - val_loss: 0.9144 - val_accuracy: 0.8597\n",
            "Epoch 406/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0216 - accuracy: 0.9923 - val_loss: 0.9024 - val_accuracy: 0.8554\n",
            "Epoch 407/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 0.9079 - val_accuracy: 0.8561\n",
            "Epoch 408/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.8841 - val_accuracy: 0.8587\n",
            "Epoch 409/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0224 - accuracy: 0.9923 - val_loss: 0.8810 - val_accuracy: 0.8565\n",
            "Epoch 410/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0218 - accuracy: 0.9924 - val_loss: 0.9187 - val_accuracy: 0.8589\n",
            "Epoch 411/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 0.9316 - val_accuracy: 0.8565\n",
            "Epoch 412/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.8946 - val_accuracy: 0.8589\n",
            "Epoch 413/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.8811 - val_accuracy: 0.8584\n",
            "Epoch 414/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.8678 - val_accuracy: 0.8595\n",
            "Epoch 415/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0187 - accuracy: 0.9935 - val_loss: 0.9446 - val_accuracy: 0.8528\n",
            "Epoch 416/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0197 - accuracy: 0.9932 - val_loss: 0.9239 - val_accuracy: 0.8600\n",
            "Epoch 417/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0195 - accuracy: 0.9935 - val_loss: 0.8799 - val_accuracy: 0.8596\n",
            "Epoch 418/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0193 - accuracy: 0.9935 - val_loss: 0.9308 - val_accuracy: 0.8569\n",
            "Epoch 419/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0200 - accuracy: 0.9931 - val_loss: 0.9365 - val_accuracy: 0.8561\n",
            "Epoch 420/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0208 - accuracy: 0.9929 - val_loss: 0.9947 - val_accuracy: 0.8399\n",
            "Epoch 421/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0207 - accuracy: 0.9926 - val_loss: 0.8985 - val_accuracy: 0.8560\n",
            "Epoch 422/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0195 - accuracy: 0.9934 - val_loss: 0.9342 - val_accuracy: 0.8546\n",
            "Epoch 423/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0182 - accuracy: 0.9936 - val_loss: 0.9278 - val_accuracy: 0.8544\n",
            "Epoch 424/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0202 - accuracy: 0.9931 - val_loss: 0.8749 - val_accuracy: 0.8597\n",
            "Epoch 425/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0214 - accuracy: 0.9925 - val_loss: 0.8721 - val_accuracy: 0.8632\n",
            "Epoch 426/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0202 - accuracy: 0.9930 - val_loss: 0.9108 - val_accuracy: 0.8589\n",
            "Epoch 427/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0211 - accuracy: 0.9925 - val_loss: 0.9534 - val_accuracy: 0.8523\n",
            "Epoch 428/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0195 - accuracy: 0.9931 - val_loss: 0.9399 - val_accuracy: 0.8536\n",
            "Epoch 429/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0206 - accuracy: 0.9929 - val_loss: 0.9699 - val_accuracy: 0.8512\n",
            "Epoch 430/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0205 - accuracy: 0.9928 - val_loss: 0.8814 - val_accuracy: 0.8609\n",
            "Epoch 431/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.9342 - val_accuracy: 0.8552\n",
            "Epoch 432/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.8865 - val_accuracy: 0.8628\n",
            "Epoch 434/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0193 - accuracy: 0.9930 - val_loss: 0.8855 - val_accuracy: 0.8603\n",
            "Epoch 435/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0198 - accuracy: 0.9931 - val_loss: 0.9099 - val_accuracy: 0.8572\n",
            "Epoch 436/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.9131 - val_accuracy: 0.8556\n",
            "Epoch 437/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0185 - accuracy: 0.9935 - val_loss: 0.9171 - val_accuracy: 0.8582\n",
            "Epoch 438/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0175 - accuracy: 0.9940 - val_loss: 0.8691 - val_accuracy: 0.8608\n",
            "Epoch 439/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0196 - accuracy: 0.9931 - val_loss: 0.9141 - val_accuracy: 0.8557\n",
            "Epoch 440/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 0.9022 - val_accuracy: 0.8589\n",
            "Epoch 441/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0190 - accuracy: 0.9935 - val_loss: 0.8874 - val_accuracy: 0.8625\n",
            "Epoch 442/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0171 - accuracy: 0.9941 - val_loss: 0.9188 - val_accuracy: 0.8587\n",
            "Epoch 443/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0175 - accuracy: 0.9938 - val_loss: 0.9578 - val_accuracy: 0.8546\n",
            "Epoch 444/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0179 - accuracy: 0.9938 - val_loss: 0.9448 - val_accuracy: 0.8558\n",
            "Epoch 445/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 0.8968 - val_accuracy: 0.8591\n",
            "Epoch 446/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.9355 - val_accuracy: 0.8556\n",
            "Epoch 447/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0194 - accuracy: 0.9935 - val_loss: 0.9200 - val_accuracy: 0.8567\n",
            "Epoch 448/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 0.8783 - val_accuracy: 0.8564\n",
            "Epoch 449/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0201 - accuracy: 0.9932 - val_loss: 0.9295 - val_accuracy: 0.8574\n",
            "Epoch 450/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0190 - accuracy: 0.9934 - val_loss: 0.8885 - val_accuracy: 0.8573\n",
            "Epoch 451/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.9334 - val_accuracy: 0.8594\n",
            "Epoch 452/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0190 - accuracy: 0.9932 - val_loss: 0.8812 - val_accuracy: 0.8588\n",
            "Epoch 453/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0172 - accuracy: 0.9937 - val_loss: 0.9437 - val_accuracy: 0.8524\n",
            "Epoch 454/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.9413 - val_accuracy: 0.8570\n",
            "Epoch 455/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.9439 - val_accuracy: 0.8596\n",
            "Epoch 456/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.8774 - val_accuracy: 0.8599\n",
            "Epoch 457/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0181 - accuracy: 0.9939 - val_loss: 0.9842 - val_accuracy: 0.8543\n",
            "Epoch 458/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.9320 - val_accuracy: 0.8598\n",
            "Epoch 459/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 0.9178 - val_accuracy: 0.8582\n",
            "Epoch 460/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.9759 - val_accuracy: 0.8572\n",
            "Epoch 461/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 0.9394 - val_accuracy: 0.8590\n",
            "Epoch 462/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0184 - accuracy: 0.9935 - val_loss: 0.9890 - val_accuracy: 0.8514\n",
            "Epoch 463/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.9979 - val_accuracy: 0.8561\n",
            "Epoch 464/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0199 - accuracy: 0.9934 - val_loss: 0.8889 - val_accuracy: 0.8603\n",
            "Epoch 465/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0176 - accuracy: 0.9936 - val_loss: 0.9030 - val_accuracy: 0.8615\n",
            "Epoch 466/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.9779 - val_accuracy: 0.8539\n",
            "Epoch 467/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.9284 - val_accuracy: 0.8552\n",
            "Epoch 468/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 0.9049 - val_accuracy: 0.8612\n",
            "Epoch 469/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 0.8831 - val_accuracy: 0.8622\n",
            "Epoch 470/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.8829 - val_accuracy: 0.8626\n",
            "Epoch 471/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.9287 - val_accuracy: 0.8576\n",
            "Epoch 472/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.9596 - val_accuracy: 0.8519\n",
            "Epoch 473/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 0.9264 - val_accuracy: 0.8570\n",
            "Epoch 474/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0192 - accuracy: 0.9930 - val_loss: 0.9141 - val_accuracy: 0.8589\n",
            "Epoch 475/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0161 - accuracy: 0.9943 - val_loss: 0.8913 - val_accuracy: 0.8626\n",
            "Epoch 476/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0165 - accuracy: 0.9941 - val_loss: 0.9468 - val_accuracy: 0.8535\n",
            "Epoch 477/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 0.8993 - val_accuracy: 0.8653\n",
            "Epoch 478/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 0.9081 - val_accuracy: 0.8620\n",
            "Epoch 479/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.9553 - val_accuracy: 0.8585\n",
            "Epoch 480/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 0.9267 - val_accuracy: 0.8565\n",
            "Epoch 481/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 0.9224 - val_accuracy: 0.8627\n",
            "Epoch 482/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.9859 - val_accuracy: 0.8553\n",
            "Epoch 483/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.9203 - val_accuracy: 0.8604\n",
            "Epoch 484/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 0.9213 - val_accuracy: 0.8592\n",
            "Epoch 485/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.9334 - val_accuracy: 0.8569\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0185 - accuracy: 0.9936 - val_loss: 0.9365 - val_accuracy: 0.8575\n",
            "Epoch 487/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.9869 - val_accuracy: 0.8517\n",
            "Epoch 488/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.9043 - val_accuracy: 0.8577\n",
            "Epoch 489/500\n",
            "391/391 [==============================] - 13s 32ms/step - loss: 0.0146 - accuracy: 0.9948 - val_loss: 0.8904 - val_accuracy: 0.8600\n",
            "Epoch 490/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.9050 - val_accuracy: 0.8615\n",
            "Epoch 491/500\n",
            "391/391 [==============================] - 13s 32ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.9182 - val_accuracy: 0.8585\n",
            "Epoch 492/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.9413 - val_accuracy: 0.8573\n",
            "Epoch 493/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.9066 - val_accuracy: 0.8615\n",
            "Epoch 494/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.8944 - val_accuracy: 0.8609\n",
            "Epoch 495/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.9194 - val_accuracy: 0.8592\n",
            "Epoch 496/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0155 - accuracy: 0.9946 - val_loss: 0.9170 - val_accuracy: 0.8591\n",
            "Epoch 497/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 0.9218 - val_accuracy: 0.8605\n",
            "Epoch 498/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.9330 - val_accuracy: 0.8566\n",
            "Epoch 499/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.9340 - val_accuracy: 0.8556\n",
            "Epoch 500/500\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.9101 - val_accuracy: 0.8611\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f482e26ddd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOE5QPW8KSHJ"
      },
      "source": [
        "若依照以上範例的設定，經過 20 輪訓練後，DNN 可以到達約 40% 的正確率，而 CNN 可以達到約 50% 的正確率。請更改 DNN 或是 CNN 的架構來改善模型。提示：\n",
        "\n",
        "1. 調整訓練輪數(`epochs`)\n",
        "2. 調整批次大小(`batch_size`)\n",
        "3. 調整學習速率(`learning_rate`)\n",
        "4. 增加層數\n",
        "5. 調整每層的神經元數量"
      ]
    }
  ]
}